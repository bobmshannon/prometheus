default_conf:
  ENV:
    CONFIG_FILE: '{{ service_home }}/var/conf/prometheus.yml'
    LOG_FILE: '{{ service_home }}/var/log/prometheus-console.log'
    LOG_LEVEL: info
    RELOAD_URL: '{{ conf.prometheus.protocol }}://{{ conf.prometheus.hostname }}:{{ conf.prometheus.port }}/-/reload'
    STORAGE_TSDB_PATH: '{{ service_home }}/var/data/'
    WEB_LISTEN_ADDRESS: '{{ conf.prometheus.address }}:{{ conf.prometheus.port }}'
  # The configuration used for rotating logs generated by Prometheus.
  logrotate:
    files:
      - filepath: '{{ conf.ENV.LOG_FILE }}'
        settings: []
    global:
      - compress
      - copytruncate
      - daily
      - rotate 7
      - size 1024M
  baseline_alerts:
    groups:
    # The set of SLS compliant service alerting rules evaluated by Prometheus.
    - name: sls.rules
      rules: []
    # The set of system baseline alerting rules evaluated by Prometheus.
    - name: system.rules
      rules:
      # Alert if an instance CPU is saturated on average for 10 minutes.
      - alert: HighCPUUsage
        expr: 100 - avg_over_time(system:core_idle{core="cpu-total"}[10m]) - avg_over_time(system:core_iowait{core="cpu-total"}[10m]) >= 95
        for: 10m
        labels:
           severity: critical
        annotations:
          description: "{{`Host {{ $labels.host }}'s CPU on average has been saturated over the last 10 minutes which is an indicator of likely performance problems caused by a CPU bottleneck.`}}"
          summary: "{{`Host {{ $labels.host }}'s CPU is saturated`}}"
      # Page if the disk is predicted to fill up within 4 hours.
      - alert: DiskWillFillIn4Hours
        expr: predict_linear(system:disk_used_percent{path!="/media"}[1h], 4 * 3600) >= 100
        for: 10m
        labels:
          severity: page
        annotations:
          description: "{{`Disk {{ $labels.path }} predicted to fill up within the next 4 hours on {{ $labels.host }}`}}"
          summary: "{{`At current rate of usage the disk {{ $labels.path }} on host {{ $labels.host }} is predicted to fill up within the next 4 hours.`}}"
      # Alert if there is a large number of inodes being used.
      - alert: HighInodeUsage
        expr: 100*system:fs_inodes_used{fstype=~"(ext.|xfs)"}/system:fs_inodes_total{fstype=~"(ext.|xfs)"} >= 80
        for: 10m
        labels:
          severity: critical
        annotations:
          summary: "{{`High inodes usage in filesystem {{ $labels.path }} on host {{ $labels.host }}`}}"
          description: "{{`A very high number of inodes are being used in the filesystem {{ $labels.path }} on host {{ $labels.host }}.`}}"
      # Alert if an instance is experiencing memory pressure.
      - alert: HostMemoryPressure
        expr: system:mem_available_percent < 5
        for: 10m
        labels:
            severity: critical
        annotations:
            summary: "{{`Memory pressure on host {{ $labels.host }}`}}"
            description: "{{`The amount of available memory for application use on host {{ $labels.host }} is very low. Hosts that run out of memory will experience stability issues caused by the kernel OOM killer.`}}"
  monitored_hosts: '{{discovered.metrics-agent[0].hostnames}}'
  prometheus:
    rule_files:
      - '{{ service_home }}/var/conf/host_alerts.yml'
      - '{{ service_home }}/var/conf/baseline_alerts.yml'
    address: 0.0.0.0
    alertmanager_scheme: '{{ discovered.alertmanager-scheme }}'
    alertmanagers: '{{ discovered.all-alertmanagers }}'
    ca_path: '{{ ssl.ca_path }}'
    evaluation_interval: 1m
    hostname: '{{ host.hostname }}'
    custom_configs: '{{ exclude }}'
    custom_scrapes: '{{ exclude }}'
    port: 9090
    protocol: http
    prometheus_metrics: '{{ discovered.prometheus-metrics }}'
    scrape_interval: 30s
    scrape_timeout: 30s
    ssl:
      ca_path: '{{ ssl.ca_path }}'
      cert_path: '{{ ssl.cert_path }}'
      pem_path: '{{ ssl.pem_path }}'
discovery:
  consumes:
    alertmanager-scheme:
      role: prometheus-alertmanager
      select: scheme
    all-alertmanagers:
      all: true
      role: prometheus-alertmanager
      select: endpoint
    metrics-agent:
      all: true
      role: metrics-agent
      stack: '*'
    prometheus-metrics:
      all: true
      role: prometheus-metrics
      stack: '*'
    prometheus-alerts:
      all: true
      role: prometheus-alerts
      stack: '*'
  produces:
    prometheus:
      endpoint: '{{ self_discovered.prometheus.hostname }}:{{ self_discovered.prometheus.port }}'
      path: ''
      port: '{{ conf.prometheus.port }}'
      role: prometheus
      scheme: '{{ conf.prometheus.protocol }}'
    prometheus-push:
      endpoint: '{{ self_discovered.prometheus.hostname}}:{{ self_discovered.prometheus.port }}'
      path: /push
      port: '{{ conf.prometheus.port }}'
      role: prometheus-push
      scheme: '{{ conf.prometheus.protocol }}'
managed_files:
  var/conf/logrotate.conf:
    live-reload: kick
    type: erb
  var/conf/prometheus.yml:
    live-reload: kick
    type: tmpl
  var/conf/baseline_alerts.yml:
    live-reload: kick
    content: baseline_alerts
    type: yaml
  var/conf/host_alerts.yml:
    live-reload: kick
    type: tmpl
