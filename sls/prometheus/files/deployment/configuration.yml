default_conf:
  ENV:
    CONFIG_FILE: '{{ service_home }}/var/conf/prometheus.yml'
    LOG_FILE: '{{ service_home }}/var/log/prometheus-console.log'
    LOG_LEVEL: info
    RELOAD_URL: '{{ conf.prometheus.protocol }}://{{ conf.prometheus.hostname }}:{{ conf.prometheus.port }}/-/reload'
    STORAGE_TSDB_PATH: '{{ service_home }}/var/data/'
    WEB_LISTEN_ADDRESS: '{{ conf.prometheus.address }}:{{ conf.prometheus.port }}'
    WEB_EXTERNAL_URL: '{{ self_discovered.prometheus.external_uri }}'
    WEB_ROUTE_PREFIX: '{{ conf.prometheus.context_path }}'
  # The configuration used for rotating logs generated by Prometheus.
  logrotate:
    files:
      - filepath: '{{ conf.ENV.LOG_FILE }}'
        settings: []
    global:
      - compress
      - copytruncate
      - daily
      - rotate 7
      - size 1024M
  baseline_alerts:
    groups:
    # The set of SLS compliant service baseline alerting rules evaluated by Prometheus.
    - name: sls.rules
      rules: []
    # The set of system baseline alerting rules evaluated by Prometheus.
    - name: system.rules
      rules:
      # Alert if an instance CPU is >=95% utilized on average for 10 minutes.
      - alert: SystemHighCPUUtilization
        expr: 100 - avg_over_time(system:core_idle{core="cpu-total"}[10m]) - avg_over_time(system:core_iowait{core="cpu-total"}[10m]) >= 95
        for: 10m
        labels:
           severity: critical
        annotations:
          summary: "{{`CPU usage on host {{ $labels.host }} >= 95% for extended period`}}"
          description: "{{`CPU usage on host {{ $labels.host }} has been {{ $value }}% utilized on average over the last 10 minutes. A saturated CPU can cause application and overall system performance issues primarily through increased run queue service times.`}}"
      # Page if disk usage is very high.
      - alert: SystemHighDiskUsage
        expr: system:disk_used_percent{path!="/media"} >= 95
        for: 10m
        labels:
          severity: page
        annotations:
          summary: "{{`Disk {{ $labels.path }} on host {{ $labels.host }} is running out of space`}}"
          description: "{{`The disk {{ $labels.path }} on host {{ $labels.host }} is currently at {{ $value }}% usage and is at risk of running out of space soon.`}}"
      # Page if the disk is predicted to fill up within 4 hours.
      - alert: SystemDiskWillFillIn4Hours
        expr: predict_linear(system:disk_used_percent{path!="/media"}[1h], 60 * 60 * 4) >= 100
        for: 10m
        labels:
          severity: page
        annotations:
          summary: "{{`Disk {{ $labels.path }} predicted to fill up within the next 4 hours on {{ $labels.host }}`}}"
          description: "{{`At current rate of usage the disk {{ $labels.path }} on host {{ $labels.host }} is predicted to fill up within the next 4 hours.`}}"
      # Page if the disk is predicted to fill up within 2 weeks.
      - alert: SystemDiskWillFillIn2Weeks
        expr: predict_linear(system:disk_used_percent{path!="/media"}[24h], 60 * 60 * 24 * 14) >= 100
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "{{`Disk {{ $labels.path }} predicted to fill up within the next 2 weeks on {{ $labels.host }}`}}"
          description: "{{`At current rate of usage the disk {{ $labels.path }} on host {{ $labels.host }} is predicted to fill up within the next 2 weeks.`}}"
      # Alert if there is a large number of inodes being used.
      - alert: SystemHighInodeUsage
        expr: 100*system:fs_inodes_used{fstype=~"(ext.|xfs)"}/system:fs_inodes_total{fstype=~"(ext.|xfs)"} >= 80
        for: 10m
        labels:
          severity: critical
        annotations:
          summary: "{{`High inodes usage in filesystem {{ $labels.path }} on host {{ $labels.host }}`}}"
          description: "{{`{{ $value }}% of inodes have been exhausted in the filesystem {{ $labels.path }} on host {{ $labels.host }}.`}}"
      # Alert if a system is experiencing memory pressure.
      - alert: SystemMemoryPressure
        expr: min_over_time(system:mem_available_percent{}[5m]) <= 10
        for: 10m
        labels:
          severity: critical
        annotations:
          summary: "{{`Memory pressure on host {{ $labels.host }}`}}"
          description: "{{`There is only {{ $value }}% amount of available memory for application use on host {{ $labels.host }}. Hosts that run out of memory will experience stability issues caused by the kernel OOM killer.`}}"
      # Alert if a system is dropping packets.
      - alert: SystemDroppedPackets
        expr: 100*(increase(system:net_drop_in{}[5m])+increase(system:net_drop_out{}[5m])+increase(system:net_packets_in_error{}[5m])+increase(system:net_packets_out_error{}[5m])) / (increase(system:net_packets_in_count{}[5m])+increase(system:net_packets_in_count{}[5m])) >= 1
        for: 10m
        labels:
          severity: critical
        annotations:
          summary: "{{`Packets being dropped on host {{ $labels.host }}`}}"
          description: "{{`The 5 minute dropped packet rate is {{ $value }}% on {{ $labels.interface }} on host {{ $labels.host }}.`}}"
      # Alert if a system has a large number of zombie processes.
      - alert: SystemZombieProcesses
        expr: system:processes_zombies > 500
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "{{`Zombie processes on host {{ $labels.host }}`}}"
          description: "{{`There are {{ $value }} zombie processes running on host {{ $labels.host }}. Zombie processes are a resource leak that can cause PID pool exhaustion on the system. These processes are typically caused by a bug in the parent process.`}}"
      # Alert if a system has a low amount of entropy.
      - alert: SystemLowEntropy
        expr: avg_over_time(system:entropy_available{}[10m]) <= 1024
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "{{`Low entropy on host {{ $labels.host }}`}}"
          description: "{{`The average number of bits available in the entropy pool over the last 10 minutes is {{ $value }} which is very low.`}}"
  monitored_hosts: '{{discovered.metrics-agent[0].hostnames}}'
  prometheus:
    rule_files:
      - '{{ service_home }}/var/conf/host_alerts.yml'
      - '{{ service_home }}/var/conf/baseline_alerts.yml'
    address: 0.0.0.0
    alertmanager_scheme: '{{ discovered.alertmanager-scheme }}'
    alertmanagers: '{{ discovered.all-alertmanagers }}'
    ca_path: '{{ ssl.ca_path }}'
    context_path: '/prometheus'
    evaluation_interval: 1m
    hostname: '{{ host.hostname }}'
    custom_configs: '{{ exclude }}'
    custom_scrapes: '{{ exclude }}'
    port: 9090
    protocol: http
    prometheus_metrics: '{{ discovered.prometheus-metrics }}'
    scrape_interval: 30s
    scrape_timeout: 30s
    ssl:
      ca_path: '{{ ssl.ca_path }}'
      cert_path: '{{ ssl.cert_path }}'
      pem_path: '{{ ssl.pem_path }}'
discovery:
  consumes:
    alertmanager-scheme:
      role: prometheus-alertmanager
      select: scheme
    all-alertmanagers:
      all: true
      role: prometheus-alertmanager
      select: endpoint
    metrics-agent:
      all: true
      role: metrics-agent
      stack: '*'
    prometheus-metrics:
      all: true
      role: prometheus-metrics
      stack: '*'
    prometheus-alerts:
      all: true
      role: prometheus-alerts
      stack: '*'
  produces:
    prometheus:
      endpoint: '{{ self_discovered.prometheus.hostname }}:{{ self_discovered.prometheus.port }}'
      path: '{{ conf.prometheus.context_path }}'
      port: '{{ conf.prometheus.port }}'
      role: prometheus
      scheme: '{{ conf.prometheus.protocol }}'
    prometheus-push:
      endpoint: '{{ self_discovered.prometheus.hostname}}:{{ self_discovered.prometheus.port }}'
      path: /push
      port: '{{ conf.prometheus.port }}'
      role: prometheus-push
      scheme: '{{ conf.prometheus.protocol }}'
managed_files:
  var/conf/logrotate.conf:
    live-reload: kick
    type: erb
  var/conf/prometheus.yml:
    live-reload: kick
    type: tmpl
  var/conf/baseline_alerts.yml:
    live-reload: kick
    content: baseline_alerts
    type: yaml
  var/conf/host_alerts.yml:
    live-reload: kick
    type: tmpl
